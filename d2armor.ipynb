{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d2armor - Analyze all armor in your Destiny 2 vault \n",
    "\n",
    "A python jupyter notebook that can analyze all armor in your Destiny 2 vault and tell you what is great and what is worth sharding.\n",
    "\n",
    "This notebook assumes that your vault information has already been downloaded into `data/profile.json` via the `d2profile.ipynb` jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the data/profile.json downloaded by `d2profile.ipynb` to load your profile containing all armor and weapons\n",
    "import os\n",
    "import json\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# assert that the json files exist\n",
    "assert os.path.exists(\n",
    "    \"data/profile.json\"\n",
    "), \"Profile file not found. Run the d2profile.ipynb notebook first to generate it.\"\n",
    "assert os.path.exists(\n",
    "    \"data/item_definitions.json\"\n",
    "), \"Item definitions file not found. Run the d2profile.ipynb notebook first to generate it.\"\n",
    "assert os.path.exists(\n",
    "    \"data/stat_definitions.json\"\n",
    "), \"Stat definitions file not found. Run the d2profile.ipynb notebook first to generate it.\"\n",
    "\n",
    "with open(\"data/profile.json\", \"r\") as file:\n",
    "    profile = json.load(file)\n",
    "\n",
    "print(\"Character profile loaded at:\", profile[\"responseMintedTimestamp\"])\n",
    "\n",
    "with open(\"data/item_definitions.json\", \"r\") as file:\n",
    "    item_definitions = json.load(file)\n",
    "\n",
    "with open(\"data/stat_definitions.json\", \"r\") as file:\n",
    "    stat_definitions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all armor pieces out of the profile.  It retrieves from the vault, character inventory, and character equipment\n",
    "from src.armor import ProfileArmor\n",
    "\n",
    "profile_armor = ProfileArmor(profile, item_definitions, stat_definitions)\n",
    "\n",
    "unfiltered_armor_dict = profile_armor.get_armor_dict()\n",
    "unfiltered_armor_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter ignored armor\n",
    "\n",
    "Ignore any armor in `data/ignored-armor.json` - if you have armor tagged as junk/infuse in DIM, you can export that as a CSV then identify the values to ignore\n",
    "Expected format is a list of values that have an `instance_id` property, ex: \n",
    "\n",
    "```\n",
    "[\n",
    "    { \"instance_id\": 6917530015478829219},\n",
    "    { \"instance_id\": 6917529815104854677}\n",
    "]\n",
    "```\n",
    "\n",
    "Other fields can be on the object, we only care about filtering `instance_id` values here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "ignored_armor = []\n",
    "if os.path.exists(\"data/ignored-armor.json\"):\n",
    "    with open(\"data/ignored-armor.json\", \"r\") as file:\n",
    "        ignored_armor = json.load(file)\n",
    "        ignored_ids = [armor[\"instance_id\"] for armor in ignored_armor]\n",
    "\n",
    "    armor_dict = {}\n",
    "    filtered_armor_dict = {}\n",
    "\n",
    "    for armor in unfiltered_armor_dict.values():\n",
    "        if armor.instance_id not in ignored_ids:\n",
    "            armor_dict[armor.instance_id] = armor\n",
    "        else:\n",
    "            filtered_armor_dict[armor.instance_id] = armor\n",
    "\n",
    "    print(\n",
    "        f\"data/ignored-armor.json contains {len(ignored_armor)} instance_id values. Filtered out {len(unfiltered_armor_dict) - len(armor_dict)} armor pieces.\"\n",
    "    )\n",
    "else:\n",
    "    print(\"No ignored armor found\")\n",
    "    armor_dict = unfiltered_armor_dict\n",
    "\n",
    "filtered_armor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a dataframe from the armor dictionary\n",
    "armor_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            **vars(armor),\n",
    "            \"total_stats\": armor.total_stats,\n",
    "            \"is_exotic\": armor.is_exotic,\n",
    "            \"class_slot\": armor.class_slot,\n",
    "        }\n",
    "        for armor in armor_dict.values()\n",
    "    ]\n",
    ")\n",
    "\n",
    "armor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph that shows total stats by class and slot for all armor in the vault.  The larger the circle, the more we have with that stat total\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Sort by class slot:\n",
    "armor_df.sort_values(\"class_slot\", ascending=True, inplace=True)\n",
    "\n",
    "# Create a color map for the classes\n",
    "color_map = {\n",
    "    \"Hunter\": mcolors.CSS4_COLORS[\"skyblue\"],\n",
    "    \"Titan\": mcolors.CSS4_COLORS[\"lightcoral\"],\n",
    "    \"Warlock\": mcolors.CSS4_COLORS[\"khaki\"],\n",
    "}\n",
    "armor_df[\"color\"] = armor_df[\"d2_class\"].map(color_map)\n",
    "\n",
    "# Calculate the counts for each 'class_slot' value\n",
    "counts = armor_df[\"class_slot\"].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Pass the counts as the 's' argument to plt.scatter()\n",
    "plt.scatter(\n",
    "    armor_df[\"class_slot\"],\n",
    "    armor_df[\"total_stats\"],\n",
    "    s=counts[armor_df[\"class_slot\"]] * 2,\n",
    "    color=armor_df[\"color\"],\n",
    ")\n",
    "plt.xlabel(\"Slot + Class\")\n",
    "plt.ylabel(\"Total Stats\")\n",
    "plt.title(\"Total Stats by Slot and Class\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ProfileOutfits which will let us calculate permutations of all outfits in our vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.armor import ProfileOutfits\n",
    "\n",
    "# uncomment if we want to see only armor that isn't exotic\n",
    "# non_exotic_armor_dict = {k: v for k, v in armor_dict.items() if not v.is_exotic}\n",
    "# profile_outfits = ProfileOutfits(non_exotic_armor_dict)\n",
    "\n",
    "# or uncomment this to use all armor in the vault\n",
    "profile_outfits = ProfileOutfits(armor_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify all armor that is eclipsed by another piece of armor and can be safely deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out all armor that has the same or worse stats than another piece of armor of the same rarity and type\n",
    "for lesser_armor, greater_armor in profile_outfits.find_eclipsed_armor():\n",
    "    print(f\"id:{lesser_armor.instance_id} OR id:{greater_armor.instance_id}\")\n",
    "    print(\n",
    "        f\"mob {lesser_armor.mobility}\\tres {lesser_armor.resilience}\\trec {lesser_armor.recovery}\\tdis {lesser_armor.discipline}\\tint {lesser_armor.intellect}\\tstr {lesser_armor.strength}\\t name {lesser_armor.item_name} <-- can be deleted\"\n",
    "    )\n",
    "    print(\n",
    "        f\"mob {greater_armor.mobility}\\tres {greater_armor.resilience}\\trec {greater_armor.recovery}\\tdis {greater_armor.discipline}\\tint {greater_armor.intellect}\\tstr {greater_armor.strength}\\t name {greater_armor.item_name} <-- is equal or better\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate all possible outfits for each class type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate outfit permutations for each class\n",
    "d2_class = \"Hunter\"\n",
    "hunter_outfits = profile_outfits.generate_class_outfits(d2_class)\n",
    "print(f\"Generated {len(hunter_outfits)} outfit permutations for {d2_class}\")\n",
    "\n",
    "d2_class = \"Titan\"\n",
    "titan_outfits = profile_outfits.generate_class_outfits(d2_class)\n",
    "print(f\"Generated {len(titan_outfits)} outfit permutations for {d2_class}\")\n",
    "\n",
    "d2_class = \"Warlock\"\n",
    "warlock_outfits = profile_outfits.generate_class_outfits(d2_class)\n",
    "print(f\"Generated {len(warlock_outfits)} outfit permutations for {d2_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick a class to work with for the rest of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify to the class you want to work with below\n",
    "# d2_class, outfits = (\"Hunter\", hunter_outfits)\n",
    "# d2_class, outfits = (\"Titan\", titan_outfits)\n",
    "d2_class, outfits = (\"Warlock\", warlock_outfits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the outfit permutations above PinnacleOutfits will generate a dataframe with weighted stats for each outfit\n",
    "# this lets us see which armor pieces are in outfits that are \"pinnacle\" (have the highest total stats for a given stat combination)\n",
    "from src.armor import PinnacleOutfits\n",
    "\n",
    "pinnacle_outfits = PinnacleOutfits(outfits)\n",
    "weighted_outfits_df = pinnacle_outfits.weighted_outfits_df\n",
    "weighted_outfits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the max value in each of the \"weighted\" columns grouped by num_artifice, then filter to those rows\n",
    "weighted_outfits_max_df = pinnacle_outfits.weighted_outfits_max_df\n",
    "weighted_outfits_max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters the weighted outfits to only those outfits that have a weighted stat total equal to the maximum stat value for that exotic_hash\n",
    "# this tells us which outfits hit that peak stat value so we can tell what armor pieces contribute\n",
    "pinnacle_outfits_df = pinnacle_outfits.pinnacle_outfits_df\n",
    "pinnacle_outfits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DIM query that will show armor for the given class that could be safely deleted\n",
    "# this is defined as armor that isn't in any pinnacle outfit for the currently selected class\n",
    "\n",
    "# iterate over the outfits in pinnacle_outfits_df and create a set of armor pieces that are in the outfits\n",
    "pinnacle_armor = set()\n",
    "for outfit in pinnacle_outfits_df.iter_rows():\n",
    "    for i in range(6, 11):\n",
    "        pinnacle_armor.add(outfit[i])\n",
    "\n",
    "# emit the values in pinnacle_armor with `id:` in front of them so they can be used in the DIM search bar and joined together with an `OR`\n",
    "dim_query = \" OR \".join([f\"id:{item}\" for item in pinnacle_armor])\n",
    "\n",
    "print(f\"is:{d2_class} is:armor NOT ({dim_query})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out the exotic pieces that we can reach triple 100s with\n",
    "\n",
    "it will emit the combinations of stats that we can reach triple 100s with for each piece of exotic armor\n",
    "\n",
    "It is actually looking for 3 stats that together are 250 points in total.  This would allow the use of five 10-point armor mods to hit triple 100\n",
    "\n",
    "There is no consideration for stat modifications that class fragments bring into the mix.  It assumes neutral stat modifications outside of armor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize an empty dictionary\n",
    "exotic_combinations = defaultdict(set)\n",
    "\n",
    "# Define the attributes\n",
    "attributes = [\"mob\", \"res\", \"rec\", \"dis\", \"int\", \"str\"]\n",
    "\n",
    "stat_column_combinations = list(itertools.combinations(range(6), 3))\n",
    "\n",
    "for outfit in pinnacle_outfits_df.iter_rows():\n",
    "    exotic_hash = outfit[11]  # Get the exotic_hash for the outfit\n",
    "\n",
    "    for perm in stat_column_combinations:\n",
    "        # Calculate the sum of the attributes\n",
    "        attr_sum = sum(outfit[attr] for attr in perm)\n",
    "\n",
    "        # If the sum is >= 250, add the permutation to the set\n",
    "        if attr_sum >= 250:\n",
    "            exotic_combinations[exotic_hash].add(perm)\n",
    "\n",
    "# create a dict of the armor_hash to the name of the armor piece\n",
    "armor_hash_to_name = {armor.item_hash: armor.item_name for armor in armor_dict.values()}\n",
    "\n",
    "# Print the exotic_combinations dictionary\n",
    "if len(exotic_combinations.items()) == 0:\n",
    "    print(\"Sorry, no triple-100s found, guess you'll have to play more\")\n",
    "else:\n",
    "    for exotic_hash, combinations in exotic_combinations.items():\n",
    "        if exotic_hash == ProfileOutfits.NO_EXOTIC_HASH:\n",
    "            print(\"No Exotic\")\n",
    "        else:\n",
    "            # iterate over the values in armor_dict to find the name of the exotic armor piece\n",
    "            print(f\"Exotic: {armor_hash_to_name[exotic_hash]} -- {exotic_hash}\")\n",
    "\n",
    "        # Sort the combinations alphabetically before printing\n",
    "        for combination in sorted(\n",
    "            combinations, key=lambda x: [attributes[i] for i in x]\n",
    "        ):\n",
    "            print([attributes[i] for i in combination])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out all Legendary Armor Pieces and the exotic stat combinations where this armor piece was in a pinnacle outfit\n",
    "\n",
    "It is sorted by the number of pinnacle outfits the armor piece was in, look at the bottom of the list for armor pieces that are only in pinnacle outfits that you don't care about\n",
    "\n",
    "If this armor piece isn't the only one that can make this stat combo, it will print the stat combination out between `~` characters\n",
    "\n",
    "If all stat combos are marked like `~res/dis/str~` that means that piece of armor can be safely replaces with another piece of armor and has no unique combinations.\n",
    "\n",
    "```\n",
    "Tusked Allegiance Hood -- Helmet -- id:6917529855693975489 -- m:2 r:20 r:10 d:23 i:2 s:8 -- total pinnacle outfits: 8 -- unique pinnacle outfits: 2\n",
    "    No Exotic - 0 - ~res/dis/str~\n",
    "    Briarbinds - 0 - ~res~\n",
    "    Necrotic Grip - 0 - ~dis/str~\n",
    "    Karnstein Armlets - 1 - res/dis\n",
    "    Aeon Soul - 0 - ~dis/str~\n",
    "    Phoenix Protocol - 1 - res/dis/str\n",
    "    Wings of Sacred Dawn - 0 - ~dis/str~\n",
    "    Rain of Fire - 0 - ~res/dis/str~\n",
    "```\n",
    " \n",
    "The Tusked Allegiance Hood was in 8 pinnacle outfits, but only 2 of them were unique to this armor piece\n",
    "- `res/dis` on Karnstein Armlets\n",
    "- `res/dis/str` on Phoenix Protocol\n",
    "\n",
    "The other stat combinations were in other armor pieces, so they are marked as not unique\n",
    "\n",
    "\n",
    "The output is in descending order, so the least valuable armor pieces are at the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import report\n",
    "import importlib\n",
    "\n",
    "importlib.reload(report)\n",
    "report.legendary_armor_to_pinnacle_outfits_report(\n",
    "    d2_class, armor_dict, pinnacle_outfits_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints out exotic armor pieces and the stat combinations where this armor piece was in a pinnacle outfit\n",
    "# sorts by exotic name so you can compare the stat combinations for each exotic\n",
    "importlib.reload(report)\n",
    "report.exotic_armor_to_pinnacle_outfits_report(\n",
    "    d2_class, armor_dict, pinnacle_outfits_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from polars import col\n",
    "\n",
    "\n",
    "# if you want to find all the outfits for a specific armor piece\n",
    "def find_exotic_outfits_df(exotic_name, armor_dict, outfits_df):\n",
    "    exotic_hash = ProfileOutfits.NO_EXOTIC_HASH\n",
    "    for armor in armor_dict.values():\n",
    "        if armor.item_name == exotic_name:\n",
    "            exotic_hash = armor.item_hash\n",
    "            break\n",
    "\n",
    "    return outfits_df.filter(col(\"exotic_hash\") == exotic_hash)\n",
    "\n",
    "\n",
    "exotic_outfits_df = find_exotic_outfits_df(\n",
    "    \"Starfire Protocol\", armor_dict, pinnacle_outfits_df\n",
    ")\n",
    "\n",
    "exotic_outfits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a particular exotic armor piece and stat combo you're interested in\n",
    "stats = [\"resilience\", \"discipline\", \"strength\"]\n",
    "weighted_column_name = \"weighted_\" + \"_\".join(stats)\n",
    "weighted_max_column_name = weighted_column_name + \"_max\"\n",
    "filtered_exotic_outfits_df = exotic_outfits_df.filter(\n",
    "    col(weighted_column_name) == col(weighted_max_column_name)\n",
    ")\n",
    "filtered_exotic_outfits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reshape the DataFrame to long format\n",
    "long_df = pinnacle_outfits_df.melt(\n",
    "    value_vars=[\n",
    "        \"mobility\",\n",
    "        \"resilience\",\n",
    "        \"recovery\",\n",
    "        \"discipline\",\n",
    "        \"intellect\",\n",
    "        \"strength\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Rename the columns to 'stat' and 'points'\n",
    "long_df = long_df.with_columns(\n",
    "    long_df[\"variable\"].alias(\"stat\"),\n",
    "    long_df[\"value\"].alias(\"points\"),\n",
    ")\n",
    "\n",
    "# Count the number of outfits for each point total for each stat\n",
    "counts_df = long_df.group_by([\"stat\", \"points\"]).agg(pl.count(\"stat\").alias(\"count\"))\n",
    "\n",
    "# Convert to pandas for easier plotting\n",
    "counts_df = counts_df.to_pandas()\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for stat in [\n",
    "    \"mobility\",\n",
    "    \"resilience\",\n",
    "    \"recovery\",\n",
    "    \"discipline\",\n",
    "    \"intellect\",\n",
    "    \"strength\",\n",
    "]:\n",
    "    stat_df = counts_df[counts_df[\"stat\"] == stat]\n",
    "    plt.scatter(\n",
    "        stat_df[\"points\"],\n",
    "        stat_df[\"count\"],  # Y-axis\n",
    "        alpha=0.5,\n",
    "        label=stat,\n",
    "    )\n",
    "plt.xlabel(\"Points\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Number of Points by Stat\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch for testing specific outfits and comparing against DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_row_weighted_vs_max(row):\n",
    "    # print the row so that we show the weighted value compared to the weighted max value\n",
    "    row = row.to_dict()\n",
    "    for key, value in row.items():\n",
    "        if not (key.startswith(\"weighted_\") or key.endswith(\"_max\")):\n",
    "            print(f\"{key}: {value[0]}\")\n",
    "        if key.startswith(\"weighted_\") and not key.endswith(\"_max\"):\n",
    "            max_key = key + \"_max\"\n",
    "            real_value = value[0]\n",
    "            max_value = row[max_key][0]\n",
    "            if real_value == max_value:\n",
    "                print(\n",
    "                    f\"{key}: {value[0]} == {row[max_key][0]} ************************************\"\n",
    "                )\n",
    "            else:\n",
    "                print(f\"{key}: {value[0]} < {row[max_key][0]}\")\n",
    "\n",
    "\n",
    "def print_outfit_stats(row):\n",
    "    helmet_id = row[\"helmet\"][0]\n",
    "    gauntlets_id = row[\"gauntlets\"][0]\n",
    "    chest_id = row[\"chest_armor\"][0]\n",
    "    leg_id = row[\"leg_armor\"][0]\n",
    "    class_item_id = row[\"class_item\"][0]\n",
    "\n",
    "    mobility = 0\n",
    "    resilience = 0\n",
    "    recovery = 0\n",
    "    discipline = 0\n",
    "    intellect = 0\n",
    "    strength = 0\n",
    "\n",
    "    for id in [helmet_id, gauntlets_id, chest_id, leg_id, class_item_id]:\n",
    "        armor = armor_dict[id]\n",
    "        mobility += armor.mobility\n",
    "        resilience += armor.resilience\n",
    "        recovery += armor.recovery\n",
    "        discipline += armor.discipline\n",
    "        intellect += armor.intellect\n",
    "        strength += armor.strength\n",
    "        print(\n",
    "            f\"{armor.mobility}\\t{armor.resilience}\\t{armor.recovery}\\t{armor.discipline}\\t{armor.intellect}\\t{armor.strength}\\t{armor.total_stats}\\t{armor.is_artifice}\\t{armor.item_name}\\t{armor.instance_id}\"\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"{mobility}\\t{resilience}\\t{recovery}\\t{discipline}\\t{intellect}\\t{strength}\\t<-- base outfit stats\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{row['mobility'][0]}\\t{row['resilience'][0]}\\t{row['recovery'][0]}\\t{row['discipline'][0]}\\t{row['intellect'][0]}\\t{row['strength'][0]}\\t<-- outfit with applied artifice + masterwork & rounded to useful tiers\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows in ploutfits_df that are duplicate rows for all fields - should not happen\n",
    "pinnacle_outfits_df.filter(pinnacle_outfits_df.is_duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one of my specific outfits I can see in DIM - shows all permutations of this outfit that have unique stat totals\n",
    "helmet_id = 6917529862437575151\n",
    "gauntlets_id = 6917529838031225999\n",
    "chest_id = 6917529838898582109\n",
    "leg_id = 6917530017559101392\n",
    "class_item_id = 6917529583788947730\n",
    "\n",
    "outfit = weighted_outfits_df.filter(\n",
    "    (weighted_outfits_df[\"helmet\"] == helmet_id)\n",
    "    & (weighted_outfits_df[\"gauntlets\"] == gauntlets_id)\n",
    "    & (weighted_outfits_df[\"chest_armor\"] == chest_id)\n",
    "    # & (weighted_outfits_df[\"leg_armor\"] == leg_id)\n",
    "    & (weighted_outfits_df[\"class_item\"] == class_item_id)\n",
    ")\n",
    "\n",
    "# for i in range(outfit.height):\n",
    "#     row = outfit[i]\n",
    "#     print_outfit_stats(row)\n",
    "#     print_row_weighted_vs_max(row)\n",
    "outfit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
